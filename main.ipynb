{
 "metadata": {
  "name": "",
  "signature": "sha256:c41ce89840ffc6b4953da29037b7c00a4e8b4b8a7ef446ddc8fbf748c44023d5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import argparse\n",
      "import cPickle\n",
      "import lasagne\n",
      "import numpy as np\n",
      "import os\n",
      "import pyprind\n",
      "import re\n",
      "import scipy\n",
      "import sys\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "import time\n",
      "from collections import Counter\n",
      "from lasagne.layers import cuda_convnet\n",
      "from nltk.corpus import stopwords\n",
      "from sklearn.cross_validation import *\n",
      "from sklearn.decomposition import *\n",
      "from sklearn.metrics import *\n",
      "from sklearn.preprocessing import *\n",
      "from theano.ifelse import ifelse\n",
      "from theano.printing import Print as pp\n",
      "from calculate_wups import dirac_measure, fuzzy_set_membership_measure, items2list, score_it, wup_measure\n",
      "from utils import *\n",
      "\n",
      "USE_SINGLE_ANSWER = True\n",
      "BATCH_SIZE = 128\n",
      "FEATURES_FILE = 'vgg/features.pkl'\n",
      "STOPWORDS = stopwords.words('english')\n",
      "\n",
      "TRAIN_FILE = 'data/daquar37/qa.37.raw.train.txt'\n",
      "TEST_FILE = 'data/daquar37/qa.37.raw.test.txt'\n",
      "IMG_LIST = [os.path.expanduser(f.strip()) for f in open('vgg/files.txt')]\n",
      "\n",
      "W2V_FILE = 'embeddings/word2vec/GoogleNews-vectors-negative300.bin'\n",
      "GLOVE_FILE = 'embeddings/glove/glove.840B.300d.txt'\n",
      "\n",
      "TYPOS = {\n",
      "    'clockes': 'clocks',\n",
      "    'toyhouse': 'toy house',\n",
      "    'benhind': 'behind',\n",
      "    'squer': 'square',\n",
      "    'liquod': 'liquid',\n",
      "    'tshirtsg': 'tshirts',\n",
      "    'firepalce': 'fireplace',\n",
      "    'corck': 'cork',\n",
      "    'viisble': 'visible',\n",
      "    'cupbaord': 'cupboard',\n",
      "    'eimage999': 'image999',\n",
      "    'beneatht': 'beneath',\n",
      "    'inbetweeng': 'in between',\n",
      "    'airconditionerg': 'air conditioner',\n",
      "    'objests': 'objects',\n",
      "    'objest': 'object'\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GeForce GTX 745\n",
        "/home/npow/code/nntools/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
        "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MAX_LEN = 0\n",
      "\n",
      "def reduce_along_dim(img, dim, weights, indicies): \n",
      "    '''\n",
      "    Perform bilinear interpolation given along the image dimension dim\n",
      "    -weights are the kernel weights \n",
      "    -indicies are the crossponding indicies location\n",
      "    return img resize along dimension dim\n",
      "    '''\n",
      "    other_dim = abs(dim-1)       \n",
      "    if other_dim == 0:  #resizing image width\n",
      "        weights  = np.tile(weights[np.newaxis,:,:,np.newaxis],(img.shape[other_dim],1,1,3))\n",
      "        out_img = img[:,indicies,:]*weights\n",
      "        out_img = np.sum(out_img,axis=2)\n",
      "    else:   # resize image height     \n",
      "        weights  = np.tile(weights[:,:,np.newaxis,np.newaxis],(1,1,img.shape[other_dim],3))\n",
      "        out_img = img[indicies,:,:]*weights\n",
      "        out_img = np.sum(out_img,axis=1)\n",
      "        \n",
      "    return out_img\n",
      "\n",
      "            \n",
      "def cubic_spline(x):\n",
      "    '''\n",
      "    Compute the kernel weights \n",
      "    See Keys, \"Cubic Convolution Interpolation for Digital Image\n",
      "    Processing,\" IEEE Transactions on Acoustics, Speech, and Signal\n",
      "    Processing, Vol. ASSP-29, No. 6, December 1981, p. 1155.\n",
      "    '''\n",
      "    absx   = np.abs(x)\n",
      "    absx2  = absx**2\n",
      "    absx3  = absx**3 \n",
      "    kernel_weight = (1.5*absx3 - 2.5*absx2 + 1) * (absx<=1) + (-0.5*absx3 + 2.5* absx2 - 4*absx + 2) * ((1<absx) & (absx<=2))\n",
      "    return kernel_weight\n",
      "    \n",
      "def contribution(in_dim_len, out_dim_len, scale ):\n",
      "    '''\n",
      "    Compute the weights and indicies of the pixels involved in the cubic interpolation along each dimension.\n",
      "    \n",
      "    output:\n",
      "    weights a list of size 2 (one set of weights for each dimension). Each item is of size OUT_DIM_LEN*Kernel_Width\n",
      "    indicies a list of size 2(one set of pixel indicies for each dimension) Each item is of size OUT_DIM_LEN*kernel_width\n",
      "    \n",
      "    note that if the entire column weights is zero, it gets deleted since those pixels don't contribute to anything\n",
      "    '''\n",
      "    kernel_width = 4\n",
      "    if scale < 1:\n",
      "        kernel_width =  4 / scale\n",
      "        \n",
      "    x_out = np.array(range(1,out_dim_len+1))  \n",
      "    #project to the input space dimension\n",
      "    u = x_out/scale + 0.5*(1-1/scale)\n",
      "    \n",
      "    #position of the left most pixel in each calculation\n",
      "    l = np.floor( u - kernel_width/2)\n",
      "  \n",
      "    #maxium number of pixels in each computation\n",
      "    p = int(np.ceil(kernel_width) + 2)\n",
      "    \n",
      "    indicies = np.zeros((l.shape[0],p), dtype = int)\n",
      "    indicies[:,0] = l\n",
      "      \n",
      "    for i in range(1,p):\n",
      "        indicies[:,i] = indicies[:,i-1]+1\n",
      "    \n",
      "    #compute the weights of the vectors\n",
      "    u = u.reshape((u.shape[0],1))\n",
      "    u = np.repeat(u,p,axis=1)\n",
      "    \n",
      "    if scale < 1:\n",
      "        weights = scale*cubic_spline(scale*(indicies-u ))\n",
      "    else:\n",
      "        weights = cubic_spline((indicies-u))\n",
      "         \n",
      "    weights_sums = np.sum(weights,1)\n",
      "    weights = weights/ weights_sums[:, np.newaxis] \n",
      "    \n",
      "    indicies = indicies - 1    \n",
      "    indicies[indicies<0] = 0                     \n",
      "    indicies[indicies>in_dim_len-1] = in_dim_len-1 #clamping the indicies at the ends\n",
      "    \n",
      "    valid_cols = np.all( weights==0, axis = 0 ) == False #find columns that are not all zeros\n",
      "    \n",
      "    indicies  = indicies[:,valid_cols]           \n",
      "    weights    = weights[:,valid_cols]\n",
      "    \n",
      "    return weights, indicies\n",
      "\n",
      "def imresize(img, cropped_width, cropped_height):\n",
      "    '''\n",
      "    Function implementing matlab's imresize functionality default behaviour\n",
      "    Cubic spline interpolation with antialiasing correction when scaling down the image.\n",
      "    \n",
      "    '''\n",
      "    \n",
      "    \n",
      "    width_scale  = float(cropped_width)  / img.shape[1]\n",
      "    height_scale = float(cropped_height) / img.shape[0] \n",
      "    \n",
      "    if len(img.shape) == 2: #Gray Scale Case\n",
      "        img = np.tile(img[:,:,np.newaxis], (1,1,3)) #Broadcast \n",
      "    \n",
      "    order   = np.argsort([height_scale, width_scale])\n",
      "    scale   = [height_scale, width_scale]\n",
      "    out_dim = [cropped_height, cropped_width] \n",
      "    \n",
      "    \n",
      "    weights  = [0,0]\n",
      "    indicies = [0,0]\n",
      "    \n",
      "    for i in range(0, 2):\n",
      "        weights[i], indicies[i] = contribution(img.shape[ i ],out_dim[i], scale[i])\n",
      "    \n",
      "    for i in range(0, len(order)):\n",
      "        img = reduce_along_dim(img, order[i], weights[order[i]], indicies[order[i]])\n",
      "        \n",
      "    return img\n",
      "\n",
      "def preprocess_image(img):\n",
      "    '''\n",
      "    Preprocess an input image before processing by the caffe module.\n",
      "    \n",
      "    \n",
      "    Preprocessing include:\n",
      "    -----------------------\n",
      "    1- Converting image to single precision data type\n",
      "    2- Resizing the input image to cropped_dimensions used in extract_features() matlab script\n",
      "    3- Reorder color Channel, RGB->BGR\n",
      "    4- Convert color scale from 0-1 to 0-255 range (actually because image type is a float the \n",
      "        actual range could be negative or >255 during the cubic spline interpolation for image resize.\n",
      "    5- Subtract the VGG dataset mean.\n",
      "    6- Reorder the image to standard caffe input dimension order ( 3xHxW) \n",
      "    '''\n",
      "    img      = img.astype(np.float32)\n",
      "    img      = imresize(img,224,224) #cropping the image\n",
      "    img      = img[:,:,[2,1,0]] #RGB-BGR\n",
      "    img      = img*255\n",
      "    \n",
      "    mean = np.array([103.939, 116.779, 123.68]) #mean of the vgg \n",
      "    \n",
      "    for i in range(0,3):\n",
      "        img[:,:,i] = img[:,:,i] - mean[i] #subtracting the mean\n",
      "    img = np.transpose(img, [2,0,1])\n",
      "    return img #HxWx3\n",
      "\n",
      "def clean(s):\n",
      "    if re.match('image[0-9]+', s):\n",
      "        return 'image'\n",
      "    if s in TYPOS:\n",
      "        return TYPOS[s]\n",
      "    return s\n",
      "\n",
      "def escapeNumber(line):\n",
      "    line = re.sub('^21$', 'twenty_one', line)\n",
      "    line = re.sub('^22$', 'twenty_two', line)\n",
      "    line = re.sub('^23$', 'twenty_three', line)\n",
      "    line = re.sub('^24$', 'twenty_four', line)\n",
      "    line = re.sub('^25$', 'twenty_five', line)\n",
      "    line = re.sub('^26$', 'twenty_six', line)\n",
      "    line = re.sub('^27$', 'twenty_seven', line)\n",
      "    line = re.sub('^28$', 'twenty_eight', line)\n",
      "    line = re.sub('^29$', 'twenty_nine', line)\n",
      "    line = re.sub('^30$', 'thirty', line)\n",
      "    line = re.sub('^11$', 'eleven', line)\n",
      "    line = re.sub('^12$', 'twelve', line)\n",
      "    line = re.sub('^13$', 'thirteen', line)\n",
      "    line = re.sub('^14$', 'fourteen', line)\n",
      "    line = re.sub('^15$', 'fifteen', line)\n",
      "    line = re.sub('^16$', 'sixteen', line)\n",
      "    line = re.sub('^17$', 'seventeen', line)\n",
      "    line = re.sub('^18$', 'eighteen', line)\n",
      "    line = re.sub('^19$', 'nineteen', line)\n",
      "    line = re.sub('^20$', 'twenty', line)\n",
      "    line = re.sub('^10$', 'ten', line)\n",
      "    line = re.sub('^0$', 'zero', line)\n",
      "    line = re.sub('^1$', 'one', line)\n",
      "    line = re.sub('^2$', 'two', line)\n",
      "    line = re.sub('^3$', 'three', line)\n",
      "    line = re.sub('^4$', 'four', line)\n",
      "    line = re.sub('^5$', 'five', line)\n",
      "    line = re.sub('^6$', 'six', line)\n",
      "    line = re.sub('^7$', 'seven', line)\n",
      "    line = re.sub('^8$', 'eight', line)\n",
      "    line = re.sub('^9$', 'nine', line)\n",
      "    return line\n",
      "\n",
      "def extract_qa(lines):\n",
      "    global MAX_LEN\n",
      "    questions = []\n",
      "    answers = []\n",
      "    imgIds = []\n",
      "    lineMax = 0\n",
      "    for i in range(0, len(lines) // 2):\n",
      "        n = i * 2\n",
      "        if ',' in lines[n + 1]:\n",
      "            # No multiple words answer for now.\n",
      "            continue\n",
      "        match = re.search('image(\\d+)', lines[n])\n",
      "        number = int((re.search('\\d+', match.group())).group())\n",
      "        line = lines[n]\n",
      "        line = re.sub(' in the image(\\d+)( \\?\\s)?', '' , line)\n",
      "        line = re.sub(' in this image(\\d+)( \\?\\s)?', '' , line)\n",
      "        line = re.sub(' on the image(\\d+)( \\?\\s)?', '' , line)\n",
      "        line = re.sub(' of the image(\\d+)( \\?\\s)?', '' , line)\n",
      "        line = re.sub(' in image(\\d+)( \\?\\s)?', '' , line)\n",
      "        line = re.sub(' image(\\d+)( \\?\\s)?', '' , line)\n",
      "        words = [clean(w) for w in line.split()]\n",
      "        line = ' '.join(words)\n",
      "        MAX_LEN = max(MAX_LEN, len(words))\n",
      "        questions.append(line)\n",
      "        answer = escapeNumber(re.sub('\\s$', '', lines[n + 1]))\n",
      "        answers.append(answer)\n",
      "        # Important! Here image id is 0-based.\n",
      "        imgIds.append(number - 1)\n",
      "    return (questions, answers, imgIds)\n",
      "\n",
      "def data_split(data, imgids, split):\n",
      "    td = []\n",
      "    vd = []\n",
      "    for (d, i) in zip(data, imgids):\n",
      "        if split[i] == 0:\n",
      "            vd.append(d)\n",
      "        else:\n",
      "            td.append(d)\n",
      "    return (td, vd)\n",
      "\n",
      "def train_valid_split(imgids):\n",
      "    split = {}\n",
      "    for i in imgids:\n",
      "        split[i] = 1\n",
      "    count = 0\n",
      "    for i in split.keys():\n",
      "        if count < len(split) / 10:\n",
      "            split[i] = 0\n",
      "        else:\n",
      "            break\n",
      "        count += 1\n",
      "    return split\n",
      "\n",
      "def load_file(fname):\n",
      "    global MAX_LEN\n",
      "    L = [line.strip() for line in open(fname)]\n",
      "    return extract_qa(L)\n",
      "\n",
      "    Q = L[0::2]\n",
      "    A = [y.split(', ') for y in L[1::2]]\n",
      "    I = []\n",
      "    for i,x in enumerate(Q):\n",
      "        words = x.split()        \n",
      "        img_id = int(re.sub('[^0-9]', '', words[-2]))-1        \n",
      "        I.append(img_id)\n",
      "        words = words[:-4]\n",
      "        words = [clean(w) for w in words]\n",
      "        Q[i] = ' '.join(words)\n",
      "        MAX_LEN = max(len(Q[i].split()), MAX_LEN)\n",
      "    if USE_SINGLE_ANSWER:\n",
      "        Q, A, I = [list(t) for t in zip(*filter(lambda z: len(z[1]) == 1, zip(Q, A, I)))]\n",
      "        A = [z[0] for z in A]\n",
      "    return Q, A, I\n",
      "\n",
      "X_train_val, Y_train_val_raw, I_train_val = load_file(TRAIN_FILE)\n",
      "X_test, Y_test_raw, I_test = load_file(TEST_FILE)\n",
      "\n",
      "split = train_valid_split(I_train_val)\n",
      "X_train, X_val = data_split(X_train_val, I_train_val, split)\n",
      "Y_train_raw, Y_val_raw = data_split(Y_train_val_raw, I_train_val, split)\n",
      "I_train, I_val = data_split(I_train_val, I_train_val, split)\n",
      "\n",
      "\"\"\"\n",
      "X_train, X_val, Y_train_raw, Y_val_raw, I_train, I_val = train_test_split(X_train_val,\n",
      "                                                                          Y_train_val_raw,\n",
      "                                                                          I_train_val,\n",
      "                                                                          test_size=512,\n",
      "                                                                          random_state=42)\n",
      "\"\"\"                                                                          \n",
      "\n",
      "dataset = { 'train': { 'q': X_train, 'y': Y_train_raw, 'img_idxs': I_train },\n",
      "            'val': { 'q': X_val, 'y': Y_val_raw, 'img_idxs': I_val },\n",
      "            'test': { 'q': X_test, 'y': Y_test_raw, 'img_idxs': I_test } }\n",
      "\n",
      "for data in dataset.keys():\n",
      "    for key in dataset[data].keys():\n",
      "        print data, key, len(dataset[data][key])\n",
      "        dataset[data][key] = pad_to_batch_size(dataset[data][key], BATCH_SIZE)\n",
      "        print data, key, len(dataset[data][key])\n",
      "\n",
      "if USE_SINGLE_ANSWER:\n",
      "    mlb = LabelBinarizer()\n",
      "else:\n",
      "    mlb = MultiLabelBinarizer()\n",
      "mlb.fit(Y_train_val_raw + Y_test_raw)\n",
      "\n",
      "for data in dataset.keys():\n",
      "    dataset[data]['y'] = mlb.transform(dataset[data]['y'])\n",
      "    \n",
      "print \"MAX_LEN: \", MAX_LEN\n",
      "print \"ANSWERS: \", len(mlb.classes_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "test q 3284\n",
        "test q 3328\n",
        "test y 3284\n",
        "test y 3328\n",
        "test img_idxs 3284\n",
        "test img_idxs 3328\n",
        "train q 3336\n",
        "train q 3456\n",
        "train y 3336\n",
        "train y 3456\n",
        "train img_idxs 3336\n",
        "train img_idxs 3456\n",
        "val q 489\n",
        "val q 512\n",
        "val y 489\n",
        "val y 512\n",
        "val img_idxs 489\n",
        "val img_idxs 512\n",
        "MAX_LEN:  28\n",
        "ANSWERS:  68\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def s_tanh(x):\n",
      "    return 1.7159 * T.tanh(x*2.0/3.0)\n",
      "\n",
      "class LSTMLayer(lasagne.layers.Layer):\n",
      "    '''\n",
      "    A long short-term memory (LSTM) layer.  Includes \"peephole connections\" and\n",
      "    forget gate.  Based on the definition in [#graves2014generating]_, which is\n",
      "    the current common definition. Gate names are taken from [#zaremba2014],\n",
      "    figure 1.\n",
      "\n",
      "    :references:\n",
      "        .. [#graves2014generating] Alex Graves, \"Generating Sequences With\n",
      "            Recurrent Neural Networks\"\n",
      "        .. [#zaremba2014] Wojciech Zaremba et al.,  \"Recurrent neural network\n",
      "           regularization\"\n",
      "    '''\n",
      "    def __init__(self, input_layer, num_units,\n",
      "                 W_in_to_ingate=lasagne.init.Normal(0.1),\n",
      "                 W_hid_to_ingate=lasagne.init.Normal(0.1),\n",
      "                 W_cell_to_ingate=lasagne.init.Normal(0.1),\n",
      "                 b_ingate=lasagne.init.Normal(0.1),\n",
      "                 nonlinearity_ingate=lasagne.nonlinearities.sigmoid,\n",
      "                 W_in_to_forgetgate=lasagne.init.Normal(0.1),\n",
      "                 W_hid_to_forgetgate=lasagne.init.Normal(0.1),\n",
      "                 W_cell_to_forgetgate=lasagne.init.Normal(0.1),\n",
      "                 b_forgetgate=lasagne.init.Normal(0.1),\n",
      "                 nonlinearity_forgetgate=lasagne.nonlinearities.sigmoid,\n",
      "                 W_in_to_cell=lasagne.init.Normal(0.1),\n",
      "                 W_hid_to_cell=lasagne.init.Normal(0.1),\n",
      "                 b_cell=lasagne.init.Normal(0.1),\n",
      "                 nonlinearity_cell=lasagne.nonlinearities.tanh,\n",
      "                 W_in_to_outgate=lasagne.init.Normal(0.1),\n",
      "                 W_hid_to_outgate=lasagne.init.Normal(0.1),\n",
      "                 W_cell_to_outgate=lasagne.init.Normal(0.1),\n",
      "                 b_outgate=lasagne.init.Normal(0.1),\n",
      "                 nonlinearity_outgate=lasagne.nonlinearities.sigmoid,\n",
      "                 nonlinearity_out=lasagne.nonlinearities.tanh,\n",
      "                 cell_init=lasagne.init.Constant(0.),\n",
      "                 hid_init=lasagne.init.Constant(0.),\n",
      "                 W_in_to_imgingate=lasagne.init.Normal(0.1),                 \n",
      "                 W_in_to_imgforgetgate=lasagne.init.Normal(0.1),\n",
      "                 W_in_to_imgcell=lasagne.init.Normal(0.1),\n",
      "                 W_in_to_imgoutgate=lasagne.init.Normal(0.1),\n",
      "                 backwards=False,\n",
      "                 learn_init=False,\n",
      "                 peepholes=True,\n",
      "                 gradient_steps=-1):\n",
      "        '''\n",
      "        Initialize an LSTM layer.  For details on what the parameters mean, see\n",
      "        (7-11) from [#graves2014generating]_.\n",
      "\n",
      "        :parameters:\n",
      "            - input_layer : layers.Layer\n",
      "                Input to this recurrent layer\n",
      "            - num_units : int\n",
      "                Number of hidden units\n",
      "            - W_in_to_ingate : function or np.ndarray or theano.shared\n",
      "                :math:`W_{xi}`\n",
      "            - W_hid_to_ingate : function or np.ndarray or theano.shared\n",
      "                :math:`W_{hi}`\n",
      "            - W_cell_to_ingate : function or np.ndarray or theano.shared\n",
      "                :math:`W_{ci}`\n",
      "            - b_ingate : function or np.ndarray or theano.shared\n",
      "                :math:`b_i`\n",
      "            - nonlinearity_ingate : function\n",
      "                :math:`\\sigma`\n",
      "            - W_in_to_forgetgate : function or np.ndarray or theano.shared\n",
      "                :math:`W_{xf}`\n",
      "            - W_hid_to_forgetgate : function or np.ndarray or theano.shared\n",
      "                :math:`W_{hf}`\n",
      "            - W_cell_to_forgetgate : function or np.ndarray or theano.shared\n",
      "                :math:`W_{cf}`\n",
      "            - b_forgetgate : function or np.ndarray or theano.shared\n",
      "                :math:`b_f`\n",
      "            - nonlinearity_forgetgate : function\n",
      "                :math:`\\sigma`\n",
      "            - W_in_to_cell : function or np.ndarray or theano.shared\n",
      "                :math:`W_{ic}`\n",
      "            - W_hid_to_cell : function or np.ndarray or theano.shared\n",
      "                :math:`W_{hc}`\n",
      "            - b_cell : function or np.ndarray or theano.shared\n",
      "                :math:`b_c`\n",
      "            - nonlinearity_cell : function or np.ndarray or theano.shared\n",
      "                :math:`\\tanh`\n",
      "            - W_in_to_outgate : function or np.ndarray or theano.shared\n",
      "                :math:`W_{io}`\n",
      "            - W_hid_to_outgate : function or np.ndarray or theano.shared\n",
      "                :math:`W_{ho}`\n",
      "            - W_cell_to_outgate : function or np.ndarray or theano.shared\n",
      "                :math:`W_{co}`\n",
      "            - b_outgate : function or np.ndarray or theano.shared\n",
      "                :math:`b_o`\n",
      "            - nonlinearity_outgate : function\n",
      "                :math:`\\sigma`\n",
      "            - nonlinearity_out : function or np.ndarray or theano.shared\n",
      "                :math:`\\tanh`\n",
      "            - cell_init : function or np.ndarray or theano.shared\n",
      "                :math:`c_0`\n",
      "            - hid_init : function or np.ndarray or theano.shared\n",
      "                :math:`h_0`\n",
      "            - backwards : boolean\n",
      "                If True, process the sequence backwards and then reverse the\n",
      "                output again such that the output from the layer is always\n",
      "                from x_1 to x_n.\n",
      "            - learn_init : boolean\n",
      "                If True, initial hidden values are learned\n",
      "            - peepholes : boolean\n",
      "                If True, the LSTM uses peephole connections.\n",
      "                When False, W_cell_to_ingate, W_cell_to_forgetgate and\n",
      "                W_cell_to_outgate are ignored.\n",
      "            - gradient_steps : int\n",
      "                Number of timesteps to include in backpropagated gradient\n",
      "                If -1, backpropagate through the entire sequence\n",
      "        '''\n",
      "\n",
      "        # Initialize parent layer\n",
      "        super(LSTMLayer, self).__init__(input_layer)\n",
      "\n",
      "        # For any of the nonlinearities, if None is supplied, use identity\n",
      "        if nonlinearity_ingate is None:\n",
      "            self.nonlinearity_ingate = nonlinearities.identity\n",
      "        else:\n",
      "            self.nonlinearity_ingate = nonlinearity_ingate\n",
      "\n",
      "        if nonlinearity_forgetgate is None:\n",
      "            self.nonlinearity_forgetgate = nonlinearities.identity\n",
      "        else:\n",
      "            self.nonlinearity_forgetgate = nonlinearity_forgetgate\n",
      "\n",
      "        if nonlinearity_cell is None:\n",
      "            self.nonlinearity_cell = nonlinearities.identity\n",
      "        else:\n",
      "            self.nonlinearity_cell = nonlinearity_cell\n",
      "\n",
      "        if nonlinearity_outgate is None:\n",
      "            self.nonlinearity_outgate = nonlinearities.identity\n",
      "        else:\n",
      "            self.nonlinearity_outgate = nonlinearity_outgate\n",
      "\n",
      "        if nonlinearity_out is None:\n",
      "            self.nonlinearity_out = nonlinearities.identity\n",
      "        else:\n",
      "            self.nonlinearity_out = nonlinearity_out\n",
      "\n",
      "        self.learn_init = learn_init\n",
      "        self.num_units = num_units\n",
      "        self.backwards = backwards\n",
      "        self.peepholes = peepholes\n",
      "        self.gradient_steps = gradient_steps\n",
      "\n",
      "        # Input dimensionality is the output dimensionality of the input layer\n",
      "        (num_batch, _, num_inputs) = self.input_layer.get_output_shape()\n",
      "\n",
      "        # Initialize parameters using the supplied args\n",
      "        self.W_in_to_ingate = self.create_param(\n",
      "            W_in_to_ingate, (num_inputs, num_units), name=\"W_in_to_ingate\")\n",
      "\n",
      "        self.W_hid_to_ingate = self.create_param(\n",
      "            W_hid_to_ingate, (num_units, num_units), name=\"W_hid_to_ingate\")\n",
      "\n",
      "        self.b_ingate = self.create_param(\n",
      "            b_ingate, (num_units), name=\"b_ingate\")\n",
      "\n",
      "        self.W_in_to_forgetgate = self.create_param(\n",
      "            W_in_to_forgetgate, (num_inputs, num_units),\n",
      "            name=\"W_in_to_forgetgate\")\n",
      "\n",
      "        self.W_hid_to_forgetgate = self.create_param(\n",
      "            W_hid_to_forgetgate, (num_units, num_units),\n",
      "            name=\"W_hid_to_forgetgate\")\n",
      "\n",
      "        self.b_forgetgate = self.create_param(\n",
      "            b_forgetgate, (num_units,), name=\"b_forgetgate\")\n",
      "\n",
      "        self.W_in_to_cell = self.create_param(\n",
      "            W_in_to_cell, (num_inputs, num_units), name=\"W_in_to_cell\")\n",
      "\n",
      "        self.W_hid_to_cell = self.create_param(\n",
      "            W_hid_to_cell, (num_units, num_units), name=\"W_hid_to_cell\")\n",
      "\n",
      "        self.b_cell = self.create_param(\n",
      "            b_cell, (num_units,), name=\"b_cell\")\n",
      "\n",
      "        self.W_in_to_outgate = self.create_param(\n",
      "            W_in_to_outgate, (num_inputs, num_units), name=\"W_in_to_outgate\")\n",
      "\n",
      "        self.W_hid_to_outgate = self.create_param(\n",
      "            W_hid_to_outgate, (num_units, num_units), name=\"W_hid_to_outgate\")\n",
      "\n",
      "        self.b_outgate = self.create_param(\n",
      "            b_outgate, (num_units,), name=\"b_outgate\")\n",
      "\n",
      "        self.W_in_to_imgingate = self.create_param(\n",
      "            W_in_to_imgingate, (num_inputs, num_units), name=\"W_in_to_imgingate\")\n",
      "        \n",
      "        self.W_in_to_imgforgetgate = self.create_param(\n",
      "            W_in_to_imgforgetgate, (num_inputs, num_units),\n",
      "            name=\"W_in_to_imgforgetgate\")\n",
      "        \n",
      "        self.W_in_to_imgcell = self.create_param(\n",
      "            W_in_to_imgcell, (num_inputs, num_units), name=\"W_in_to_imgcell\")\n",
      "        \n",
      "        self.W_in_to_imgoutgate = self.create_param(\n",
      "            W_in_to_imgoutgate, (num_inputs, num_units), name=\"W_in_to_imgoutgate\")        \n",
      "\n",
      "        # Stack input to gate weight matrices into a (num_inputs, 4*num_units)\n",
      "        # matrix, which speeds up computation\n",
      "        self.W_in_to_gates = T.concatenate(\n",
      "            [self.W_in_to_ingate, self.W_in_to_forgetgate,\n",
      "            self.W_in_to_cell, self.W_in_to_outgate], axis=1)\n",
      "        \n",
      "        self.W_in_to_imggates = T.concatenate(\n",
      "            [self.W_in_to_imgingate, self.W_in_to_imgforgetgate,\n",
      "            self.W_in_to_imgcell, self.W_in_to_imgoutgate], axis=1)\n",
      "            \n",
      "        # Same for hidden to gate weight matrices\n",
      "        self.W_hid_to_gates = T.concatenate(\n",
      "            [self.W_hid_to_ingate, self.W_hid_to_forgetgate,\n",
      "            self.W_hid_to_cell, self.W_hid_to_outgate, ], axis=1)\n",
      "\n",
      "        # Stack gate biases into a (4*num_units) vector\n",
      "        self.b_gates = T.concatenate(\n",
      "            [self.b_ingate, self.b_forgetgate,\n",
      "            self.b_cell, self.b_outgate], axis=0)\n",
      "\n",
      "        # Initialize peephole (cell to gate) connections.  These are\n",
      "        # elementwise products with the cell state, so they are represented as\n",
      "        # vectors.\n",
      "        if self.peepholes:\n",
      "            self.W_cell_to_ingate = self.create_param(\n",
      "                W_cell_to_ingate, (num_units), name=\"W_cell_to_ingate\")\n",
      "\n",
      "            self.W_cell_to_forgetgate = self.create_param(\n",
      "                W_cell_to_forgetgate, (num_units), name=\"W_cell_to_forgetgate\")\n",
      "\n",
      "            self.W_cell_to_outgate = self.create_param(\n",
      "                W_cell_to_outgate, (num_units), name=\"W_cell_to_outgate\")\n",
      "\n",
      "        # Setup initial values for the cell and the hidden units\n",
      "        self.cell_init = self.create_param(\n",
      "            cell_init, (num_batch, num_units), name=\"cell_init\")\n",
      "        self.hid_init = self.create_param(\n",
      "            hid_init, (num_batch, num_units), name=\"hid_init\")\n",
      "\n",
      "    def get_params(self):\n",
      "        '''\n",
      "        Get all parameters of this layer.\n",
      "\n",
      "        :returns:\n",
      "            - params : list of theano.shared\n",
      "                List of all parameters\n",
      "        '''\n",
      "        params = self.get_weight_params() + self.get_bias_params()\n",
      "        if self.peepholes:\n",
      "            params.extend(self.get_peephole_params())\n",
      "\n",
      "        if self.learn_init:\n",
      "            params.extend(self.get_init_params())\n",
      "\n",
      "        return params\n",
      "\n",
      "    def get_weight_params(self):\n",
      "        '''\n",
      "        Get all weight matrix parameters of this layer\n",
      "\n",
      "        :returns:\n",
      "            - weight_params : list of theano.shared\n",
      "                List of all weight matrix parameters\n",
      "        '''\n",
      "        return [self.W_in_to_ingate,\n",
      "                self.W_hid_to_ingate,\n",
      "                self.W_in_to_forgetgate,\n",
      "                self.W_hid_to_forgetgate,\n",
      "                self.W_in_to_cell,\n",
      "                self.W_hid_to_cell,\n",
      "                self.W_in_to_outgate,\n",
      "                self.W_hid_to_outgate,                \n",
      "                self.W_in_to_imgingate,\n",
      "                self.W_in_to_imgforgetgate,\n",
      "                self.W_in_to_imgcell,\n",
      "                self.W_in_to_imgoutgate\n",
      "                ]\n",
      "\n",
      "    def get_peephole_params(self):\n",
      "        '''\n",
      "        Get all peephole connection parameters of this layer.\n",
      "\n",
      "        :returns:\n",
      "            - peephole_params : list of theano.shared\n",
      "                List of all peephole parameters.  If this LSTM layer doesn't\n",
      "                use peephole connections (peepholes=False), then an empty list\n",
      "                is returned.\n",
      "        '''\n",
      "        if self.peepholes:\n",
      "            return [self.W_cell_to_ingate,\n",
      "                    self.W_cell_to_forgetgate,\n",
      "                    self.W_cell_to_outgate]\n",
      "        else:\n",
      "            return []\n",
      "\n",
      "    def get_init_params(self):\n",
      "        '''\n",
      "        Get all initital state parameters of this layer.\n",
      "\n",
      "        :returns:\n",
      "            - init_params : list of theano.shared\n",
      "                List of all initial parameters\n",
      "        '''\n",
      "        return [self.hid_init, self.cell_init]\n",
      "\n",
      "    def get_bias_params(self):\n",
      "        '''\n",
      "        Get all bias parameters of this layer.\n",
      "\n",
      "        :returns:\n",
      "            - bias_params : list of theano.shared\n",
      "                List of all bias parameters\n",
      "        '''\n",
      "        return [self.b_ingate, self.b_forgetgate,\n",
      "                self.b_cell, self.b_outgate]\n",
      "\n",
      "    def get_output_shape_for(self, input_shape):\n",
      "        '''\n",
      "        Compute the expected output shape given the input.\n",
      "\n",
      "        :parameters:\n",
      "            - input_shape : tuple\n",
      "                Dimensionality of expected input\n",
      "\n",
      "        :returns:\n",
      "            - output_shape : tuple\n",
      "                Dimensionality of expected outputs given input_shape\n",
      "        '''\n",
      "        return (input_shape[0], input_shape[1], self.num_units)\n",
      "\n",
      "    def get_output_for(self, input, mask=None, e_imgfeats=0, *args, **kwargs):\n",
      "        '''\n",
      "        Compute this layer's output function given a symbolic input variable\n",
      "\n",
      "        :parameters:\n",
      "            - input : theano.TensorType\n",
      "                Symbolic input variable\n",
      "            - mask : theano.TensorType\n",
      "                Theano variable denoting whether each time step in each\n",
      "                sequence in the batch is part of the sequence or not.  If None,\n",
      "                then it assumed that all sequences are of the same length.  If\n",
      "                not all sequences are of the same length, then it must be\n",
      "                supplied as a matrix of shape (n_batch, n_time_steps) where\n",
      "                `mask[i, j] = 1` when `j <= (length of sequence i)` and\n",
      "                `mask[i, j] = 0` when `j > (length of sequence i)`.\n",
      "\n",
      "        :returns:\n",
      "            - layer_output : theano.TensorType\n",
      "                Symbolic output variable\n",
      "        '''\n",
      "        # Treat all layers after the first as flattened feature dimensions\n",
      "        if input.ndim > 3:\n",
      "            input = input.reshape((input.shape[0], input.shape[1],\n",
      "                                   T.prod(input.shape[2:])))\n",
      "\n",
      "        # Because scan iterates over the first dimension we dimshuffle to\n",
      "        # (n_time_steps, n_batch, n_features)\n",
      "        input = input.dimshuffle(1, 0, 2)\n",
      "\n",
      "        # Because the input is given for all time steps, we can precompute\n",
      "        # the inputs to the gates before scanning.\n",
      "        # input is dimshuffled to (n_time_steps, n_batch, n_features)\n",
      "        # W_in_to_gates is (n_features, 4*num_units). input_dot_W is then\n",
      "        # (n_time_steps, n_batch, 4*num_units).\n",
      "        input_dot_W = T.dot(input, self.W_in_to_gates) + self.b_gates\n",
      "        input_dot_W_img = T.dot(input, self.W_in_to_imggates) + self.b_gates\n",
      "\n",
      "        # input_dot_w is (n_batch, n_time_steps, 4*num_units). We define a\n",
      "        # slicing function that extract the input to each LSTM gate\n",
      "        def slice_w(x, n):\n",
      "            return x[:, n*self.num_units:(n+1)*self.num_units]\n",
      "\n",
      "        # Create single recurrent computation step function\n",
      "        # input_dot_W_n is the n'th timestep of the input, dotted with W\n",
      "        # The step function calculates the following:\n",
      "        #\n",
      "        # i_t = \\sigma(W_{xi}x_t + W_{hi}h_{t-1} + W_{ci}c_{t-1} + b_i)\n",
      "        # f_t = \\sigma(W_{xf}x_t + W_{hf}h_{t-1} + W_{cf}c_{t-1} + b_f)\n",
      "        # c_t = f_tc_{t - 1} + i_t\\tanh(W_{xc}x_t + W_{hc}h_{t-1} + b_c)\n",
      "        # o_t = \\sigma(W_{xo}x_t + W_{ho}h_{t-1} + W_{co}c_t + b_o)\n",
      "        # h_t = o_t \\tanh(c_t)\n",
      "        def step(input_dot_W_n, input_dot_W_img_n, cell_previous, hid_previous):\n",
      "\n",
      "            # Calculate gates pre-activations and slice\n",
      "            gates = input_dot_W_n + T.dot(hid_previous, self.W_hid_to_gates)\n",
      "            imggates = input_dot_W_img_n + T.dot(hid_previous, self.W_hid_to_gates)\n",
      "            # Extract the pre-activation gate values\n",
      "            ingate = slice_w(gates, 0) + lasagne.nonlinearities.sigmoid(slice_w(imggates, 0)) * e_imgfeats\n",
      "            forgetgate = slice_w(gates, 1) + lasagne.nonlinearities.sigmoid(slice_w(imggates, 1)) * e_imgfeats\n",
      "            cell_input = slice_w(gates, 2) + lasagne.nonlinearities.sigmoid(slice_w(imggates, 2)) * e_imgfeats\n",
      "            outgate = slice_w(gates, 3) + lasagne.nonlinearities.sigmoid(slice_w(imggates, 3)) * e_imgfeats\n",
      "\n",
      "            if self.peepholes:\n",
      "                # Compute peephole connections\n",
      "                ingate += cell_previous*self.W_cell_to_ingate\n",
      "                forgetgate += cell_previous*self.W_cell_to_forgetgate\n",
      "\n",
      "            # Apply nonlinearities\n",
      "            ingate = self.nonlinearity_ingate(ingate)\n",
      "            forgetgate = self.nonlinearity_forgetgate(forgetgate)\n",
      "            cell_input = self.nonlinearity_cell(cell_input)\n",
      "            outgate = self.nonlinearity_outgate(outgate)\n",
      "\n",
      "            # Compute new cell value\n",
      "            cell = forgetgate*cell_previous + ingate*cell_input\n",
      "            if self.peepholes:\n",
      "                outgate += cell*self.W_cell_to_outgate\n",
      "            # Compute new hidden unit activation\n",
      "            hid = outgate*self.nonlinearity_out(cell)\n",
      "            return [cell, hid]\n",
      "\n",
      "        def step_masked(input_dot_W_n, input_dot_W_img_n, mask, cell_previous, hid_previous):\n",
      "\n",
      "            cell, hid = step(input_dot_W_n, input_dot_W_img_n, cell_previous, hid_previous)\n",
      "\n",
      "            # If mask is 0, use previous state until mask = 1 is found.\n",
      "            # This propagates the layer initial state when moving backwards\n",
      "            # until the end of the sequence is found.\n",
      "            not_mask = 1 - mask\n",
      "            cell = cell*mask + cell_previous*not_mask\n",
      "            hid = hid*mask + hid_previous*not_mask\n",
      "\n",
      "            return [cell, hid]\n",
      "\n",
      "        if self.backwards and mask is not None:\n",
      "            # mask is given as (batch_size, seq_len). Because scan iterates\n",
      "            # over first dimension, we dimshuffle to (seq_len, batch_size) and\n",
      "            # add a broadcastable dimension\n",
      "            mask = mask.dimshuffle(1, 0, 'x')\n",
      "            sequences = [input_dot_W, input_dot_W_img, mask]\n",
      "            step_fun = step_masked\n",
      "        else:\n",
      "            sequences = [input_dot_W, input_dot_W_img]\n",
      "            step_fun = step\n",
      "\n",
      "        # Scan op iterates over first dimension of input and repeatedly\n",
      "        # applies the step function\n",
      "        output = theano.scan(step_fun, sequences=sequences,\n",
      "                             outputs_info=[self.cell_init, self.hid_init],\n",
      "                             go_backwards=self.backwards,\n",
      "                             truncate_gradient=self.gradient_steps)[0][1]\n",
      "\n",
      "        # Now, dimshuffle back to (n_batch, n_time_steps, n_features))\n",
      "        output = output.dimshuffle(1, 0, 2)\n",
      "\n",
      "        # if scan is backward reverse the output\n",
      "        if self.backwards:\n",
      "            output = output[:, ::-1, :]\n",
      "\n",
      "        return output\n",
      "\n",
      "class GradClip(theano.compile.ViewOp):\n",
      "\n",
      "    def __init__(self, clip_lower_bound, clip_upper_bound):\n",
      "        self.clip_lower_bound = clip_lower_bound\n",
      "        self.clip_upper_bound = clip_upper_bound\n",
      "        assert(self.clip_upper_bound >= self.clip_lower_bound)\n",
      "\n",
      "    def grad(self, args, g_outs):\n",
      "        def pgrad(g_out):\n",
      "            g_out = T.clip(g_out, self.clip_lower_bound, self.clip_upper_bound)\n",
      "            g_out = ifelse(T.any(T.isnan(g_out)), T.ones_like(g_out)*0.00001, g_out)\n",
      "            return g_out\n",
      "        return [pgrad(g_out) for g_out in g_outs]\n",
      "\n",
      "gradient_clipper = GradClip(-10.0, 10.0)\n",
      "#T.opt.register_canonicalize(theano.gof.OpRemove(gradient_clipper), name='gradient_clipper')\n",
      "\n",
      "def adam(loss, all_params, learning_rate=0.001, b1=0.9, b2=0.999, e=1e-8,\n",
      "         gamma=1-1e-8):\n",
      "    \"\"\"\n",
      "    ADAM update rules\n",
      "    Default values are taken from [Kingma2014]\n",
      "\n",
      "    References:\n",
      "    [Kingma2014] Kingma, Diederik, and Jimmy Ba.\n",
      "    \"Adam: A Method for Stochastic Optimization.\"\n",
      "    arXiv preprint arXiv:1412.6980 (2014).\n",
      "    http://arxiv.org/pdf/1412.6980v4.pdf\n",
      "\n",
      "    \"\"\"\n",
      "    updates = []\n",
      "    all_grads = theano.grad(gradient_clipper(loss), all_params)\n",
      "    alpha = learning_rate\n",
      "    t = theano.shared(np.float32(1))\n",
      "    b1_t = b1*gamma**(t-1)   #(Decay the first moment running average coefficient)\n",
      " \n",
      "    for theta_previous, g in zip(all_params, all_grads):\n",
      "        m_previous = theano.shared(np.zeros(theta_previous.get_value().shape,\n",
      "                                            dtype=theano.config.floatX))\n",
      "        v_previous = theano.shared(np.zeros(theta_previous.get_value().shape,\n",
      "                                            dtype=theano.config.floatX))\n",
      " \n",
      "        m = b1_t*m_previous + (1 - b1_t)*g                             # (Update biased first moment estimate)\n",
      "        v = b2*v_previous + (1 - b2)*g**2                              # (Update biased second raw moment estimate)\n",
      "        m_hat = m / (1-b1**t)                                          # (Compute bias-corrected first moment estimate)\n",
      "        v_hat = v / (1-b2**t)                                          # (Compute bias-corrected second raw moment estimate)\n",
      "        theta = theta_previous - (alpha * m_hat) / (T.sqrt(v_hat) + e) #(Update parameters)\n",
      " \n",
      "        updates.append((m_previous, m))\n",
      "        updates.append((v_previous, v))\n",
      "        updates.append((theta_previous, theta) )\n",
      "    updates.append((t, t + 1.))\n",
      "    return updates\n",
      "\n",
      "class Model:\n",
      "    def __init__(self,\n",
      "                 data,\n",
      "                 U,\n",
      "                 V,\n",
      "                 num_output,\n",
      "                 img_w=300,\n",
      "                 hidden_size=100,\n",
      "                 batch_size=32,\n",
      "                 lr=0.001,\n",
      "                 fine_tune_W=True,\n",
      "                 optimizer='adam',\n",
      "                 use_lstm=True,\n",
      "                 is_bidirectional=False,\n",
      "                 learn_init=False,\n",
      "                 use_peepholes=True):\n",
      "        self.data = data\n",
      "        self.batch_size = batch_size\n",
      "        img_h = MAX_LEN\n",
      "        \n",
      "        index = T.iscalar() \n",
      "        q = T.imatrix('q')\n",
      "        y = T.imatrix('y')        \n",
      "        img_idxs = T.ivector('img_idxs')\n",
      "        q_seqlen = T.ivector('q_seqlen')\n",
      "        #img_features = theano.shared(V, name='img_features', borrow=True)\n",
      "        imgs = theano.shared(V, name='imgs', borrow=True)\n",
      "        embeddings = theano.shared(U, name='embeddings', borrow=True)\n",
      "        zero_vec_tensor = T.fvector()\n",
      "        self.zero_vec = np.zeros(img_w, dtype=theano.config.floatX)\n",
      "        self.set_zero = theano.function([zero_vec_tensor], updates=[(embeddings, T.set_subtensor(embeddings[0,:], zero_vec_tensor))])\n",
      "        \n",
      "        q_input = embeddings[q.flatten()].reshape((q.shape[0], q.shape[1], embeddings.shape[1]))\n",
      "        \n",
      "        l_in = lasagne.layers.InputLayer(shape=(batch_size, img_h, img_w))        \n",
      "        if is_bidirectional:\n",
      "            raise 'Bidirectional unsupported'\n",
      "        else:\n",
      "            if use_lstm:\n",
      "                l_dropout = lasagne.layers.DropoutLayer(l_in, p=0.5)\n",
      "                l_recurrent = LSTMLayer(l_dropout,\n",
      "                                        hidden_size,\n",
      "                                        W_in_to_ingate=lasagne.init.Orthogonal(),\n",
      "                                        W_hid_to_ingate=lasagne.init.Orthogonal(),\n",
      "                                        W_cell_to_ingate=lasagne.init.Orthogonal(),\n",
      "                                        W_in_to_forgetgate=lasagne.init.Orthogonal(),\n",
      "                                        W_hid_to_forgetgate=lasagne.init.Orthogonal(),\n",
      "                                        W_cell_to_forgetgate=lasagne.init.Orthogonal(),\n",
      "                                        W_in_to_cell=lasagne.init.Orthogonal(),\n",
      "                                        W_hid_to_cell=lasagne.init.Orthogonal(),\n",
      "                                        W_in_to_outgate=lasagne.init.Orthogonal(),\n",
      "                                        W_hid_to_outgate=lasagne.init.Orthogonal(),\n",
      "                                        W_cell_to_outgate=lasagne.init.Orthogonal(),\n",
      "                                        W_in_to_imgingate=lasagne.init.Orthogonal(),\n",
      "                                        W_in_to_imgforgetgate=lasagne.init.Orthogonal(),\n",
      "                                        W_in_to_imgcell=lasagne.init.Orthogonal(),\n",
      "                                        W_in_to_imgoutgate=lasagne.init.Orthogonal(),                                        \n",
      "                                        nonlinearity_ingate=lasagne.nonlinearities.sigmoid,\n",
      "                                        nonlinearity_forgetgate=lasagne.nonlinearities.sigmoid,\n",
      "                                        nonlinearity_outgate=lasagne.nonlinearities.sigmoid,\n",
      "                                        nonlinearity_cell=s_tanh,\n",
      "                                        nonlinearity_out=s_tanh,\n",
      "                                        backwards=False,\n",
      "                                        learn_init=learn_init,\n",
      "                                        peepholes=use_peepholes)\n",
      "                l_recurrent = lasagne.layers.DropoutLayer(l_recurrent, p=0.5)                \n",
      "            else:\n",
      "                raise 'RNN Unsupported'\n",
      "        \n",
      "        l_combined_in = lasagne.layers.InputLayer(shape=(batch_size, hidden_size))\n",
      "        if USE_SINGLE_ANSWER:\n",
      "            l_out = lasagne.layers.DenseLayer(l_combined_in,\n",
      "                                              num_units=num_output,\n",
      "                                              W=lasagne.init.Orthogonal(),\n",
      "                                              nonlinearity=lasagne.nonlinearities.softmax)\n",
      "        else:\n",
      "            l_out = lasagne.layers.DenseLayer(l_combined_in,\n",
      "                                              num_units=num_output,\n",
      "                                              W=lasagne.init.Uniform(0.025),\n",
      "                                              nonlinearity=lasagne.nonlinearities.sigmoid)\n",
      "            \n",
      "        l_img_in = lasagne.layers.InputLayer(shape=(batch_size, 3, 224, 224))\n",
      "                                             \n",
      "        l_img_in = cuda_convnet.bc01_to_c01b(l_img_in)\n",
      "\n",
      "        l_conv1 = cuda_convnet.Conv2DCCLayer(\n",
      "                l_img_in,\n",
      "                num_filters=32,\n",
      "                filter_size=(8,8),\n",
      "                stride=(4,4),\n",
      "                nonlinearity=lasagne.nonlinearities.rectify,\n",
      "                W=lasagne.init.Uniform(0.01),\n",
      "                b=lasagne.init.Constant(0.1),\n",
      "                dimshuffle=False\n",
      "                )\n",
      "        \n",
      "        l_conv2 = cuda_convnet.Conv2DCCLayer(\n",
      "                l_conv1,\n",
      "                num_filters=64,\n",
      "                filter_size=(4,4),\n",
      "                stride=(2,2),\n",
      "                nonlinearity=lasagne.nonlinearities.rectify,\n",
      "                W=lasagne.init.Uniform(0.01),\n",
      "                b=lasagne.init.Constant(0.1),\n",
      "                dimshuffle=False\n",
      "                )\n",
      "\n",
      "        l_conv3 = cuda_convnet.Conv2DCCLayer(\n",
      "                l_conv2,\n",
      "                num_filters=64,\n",
      "                filter_size=(3,3),\n",
      "                stride=(1,1),\n",
      "                nonlinearity=lasagne.nonlinearities.rectify,\n",
      "                W=lasagne.init.Uniform(0.01),\n",
      "                b=lasagne.init.Constant(0.1),\n",
      "                dimshuffle=False\n",
      "                )\n",
      "\n",
      "        l_conv3 = cuda_convnet.c01b_to_bc01(l_conv3)        \n",
      "        \n",
      "        l_transform = lasagne.layers.DenseLayer(l_conv3,\n",
      "                                                num_units=hidden_size,\n",
      "                                                W=lasagne.init.Orthogonal(),\n",
      "                                                nonlinearity=lasagne.nonlinearities.rectify)\n",
      "        \n",
      "        l_transform = lasagne.layers.DropoutLayer(l_transform, p=0.5)\n",
      "\n",
      "        e_imgfeats = l_transform.get_output(imgs[img_idxs]).reshape((batch_size, hidden_size))\n",
      "            \n",
      "        e_question = l_recurrent.get_output(q_input, e_imgfeats=e_imgfeats, deterministic=False)[T.arange(batch_size), q_seqlen].reshape((q.shape[0], hidden_size))\n",
      "        e_question_det = l_recurrent.get_output(q_input, e_imgfeats=e_imgfeats, deterministic=True)[T.arange(batch_size), q_seqlen].reshape((q.shape[0], hidden_size))   \n",
      "        probas = l_out.get_output(e_question, determinstic=False)\n",
      "        probas = T.clip(probas, 1e-7, 1.0-1e-7)\n",
      "        probas_det = l_out.get_output(e_question_det, determinstic=True)\n",
      "        probas_det = T.clip(probas_det, 1e-7, 1.0-1e-7)\n",
      "                \n",
      "        cost = T.nnet.binary_crossentropy(probas, y).sum(axis=1).mean()\n",
      "        cost_det = T.nnet.binary_crossentropy(probas_det, y).sum(axis=1).mean()\n",
      "       \n",
      "        params = lasagne.layers.get_all_params(l_out) + lasagne.layers.get_all_params(l_recurrent)\n",
      "        params += lasagne.layers.get_all_params(l_transform)\n",
      "        if fine_tune_W:\n",
      "            params += [embeddings]\n",
      "            \n",
      "        if 'adam' == optimizer:\n",
      "            updates = adam(cost, params, learning_rate=lr)\n",
      "        elif 'rmsprop' == optimizer:\n",
      "            updates = lasagne.updates.rmsprop(cost, params)\n",
      "        else:\n",
      "            raise 'Unsupported optimizer'\n",
      "            \n",
      "        self.shared_data = {}        \n",
      "        self.shared_data['q'] = theano.shared(np.zeros((batch_size, MAX_LEN), dtype=np.int32), borrow=True)\n",
      "        self.shared_data['y'] = theano.shared(np.zeros((batch_size, num_output), dtype=np.int32), borrow=True)\n",
      "        for key in ['q_seqlen', 'img_idxs']:\n",
      "            self.shared_data[key] = theano.shared(np.zeros((batch_size,), dtype=np.int32), borrow=True)\n",
      "\n",
      "        givens = {\n",
      "            q: self.shared_data['q'],\n",
      "            y: self.shared_data['y'],\n",
      "            q_seqlen: self.shared_data['q_seqlen'],\n",
      "            img_idxs: self.shared_data['img_idxs']\n",
      "        }\n",
      "        self.train_model = theano.function([], cost, updates=updates, givens=givens, on_unused_input='warn')\n",
      "        self.get_probas = theano.function([], probas_det, givens=givens, on_unused_input='warn')\n",
      "        self.get_cost = theano.function([], cost_det, givens=givens, on_unused_input='warn')\n",
      "        \n",
      "    def get_batch(self, dataset, index, max_l=MAX_LEN):\n",
      "        seqlen = np.zeros((self.batch_size,), dtype=np.int32)\n",
      "        batch = np.zeros((self.batch_size, max_l), dtype=np.int32)\n",
      "        data = dataset[index*self.batch_size:(index+1)*self.batch_size]\n",
      "        for i,row in enumerate(data):\n",
      "            row = row[:max_l]\n",
      "            batch[i,0:len(row)] = row\n",
      "            seqlen[i] = len(row)-1\n",
      "        return batch, seqlen\n",
      "    \n",
      "    def set_shared_variables(self, dataset, index):\n",
      "        q, q_seqlen = self.get_batch(dataset['q'], index)        \n",
      "        num_rows = len(dataset['img_idxs'][index*self.batch_size:(index+1)*self.batch_size])\n",
      "        \n",
      "        img_idxs = np.zeros((self.batch_size,), dtype=np.int32)\n",
      "        y = np.zeros((self.batch_size, dataset['y'].shape[1]), dtype=np.int32)\n",
      "        img_idxs[:num_rows] = dataset['img_idxs'][index*self.batch_size:(index+1)*self.batch_size]\n",
      "        y[:num_rows] = dataset['y'][index*self.batch_size:(index+1)*self.batch_size]\n",
      "        \n",
      "        self.shared_data['q'].set_value(q)\n",
      "        self.shared_data['y'].set_value(y)\n",
      "        self.shared_data['q_seqlen'].set_value(q_seqlen)\n",
      "        self.shared_data['img_idxs'].set_value(img_idxs)\n",
      "\n",
      "    def compute_probas(self, dataset, index):\n",
      "        self.set_shared_variables(dataset, index)\n",
      "        return self.get_probas()\n",
      "    \n",
      "    def compute_cost(self, dataset, index):\n",
      "        self.set_shared_variables(dataset, index)\n",
      "        return self.get_cost()    \n",
      "    \n",
      "    def compute_wups_score(self, input_gt, input_pred, thresh):\n",
      "        if thresh == -1:\n",
      "            our_element_membership = dirac_measure\n",
      "        else:\n",
      "            our_element_membership = lambda x, y: wup_measure(x, y, thresh)\n",
      "        our_set_membership = lambda x, A: fuzzy_set_membership_measure(x, A, our_element_membership)\n",
      "        score_list = [score_it(items2list(ta), items2list(pa), our_set_membership) for (ta, pa) in zip(input_gt, input_pred)]\n",
      "        return float(sum(score_list)) / float(len(score_list))\n",
      "    \n",
      "    def compute_wups_scores(self, probas, y, thresholds=[0.9, 0.0]):\n",
      "        y_pred = np.argmax(probas, axis=1)\n",
      "        y_true = np.argmax(y, axis=1)\n",
      "        y_pred_labels = [mlb.classes_[k] for k in y_pred]\n",
      "        y_true_labels = [mlb.classes_[k] for k in y_true]\n",
      "        \n",
      "        return [self.compute_wups_score(y_true_labels, y_pred_labels, thresh) for thresh in thresholds]\n",
      "    \n",
      "    def compute_accuracy_score(self, probas, y):\n",
      "        y_pred = np.argmax(probas, axis=1)\n",
      "        y_true = np.argmax(y, axis=1)\n",
      "        return np.sum(y_pred == y_true) / len(y_pred)\n",
      "        \n",
      "    def train(self, n_epochs=100, shuffle_batch=False):\n",
      "        epoch = 0\n",
      "        best_val_acc = 0\n",
      "        best_val_cost = float('inf')\n",
      "        \n",
      "        n_train_batches = len(self.data['train']['y']) // self.batch_size\n",
      "        n_val_batches = len(self.data['val']['y']) // self.batch_size\n",
      "        n_test_batches = int(np.ceil(len(self.data['test']['y']) // self.batch_size))\n",
      "\n",
      "        while (epoch < n_epochs):\n",
      "            epoch += 1\n",
      "            indices = range(n_train_batches)\n",
      "            if shuffle_batch:\n",
      "                indices = np.random.permutation(indices)\n",
      "            #bar = pyprind.ProgBar(len(indices), monitor=True)\n",
      "            total_cost = 0\n",
      "            start_time = time.time()\n",
      "            for minibatch_index in indices:\n",
      "                self.set_shared_variables(self.data['train'], minibatch_index)\n",
      "                cost_epoch = self.train_model()\n",
      "                total_cost += cost_epoch\n",
      "                self.set_zero(self.zero_vec)\n",
      "                #bar.update()\n",
      "            end_time = time.time()\n",
      "            print \"cost: \", (total_cost / len(indices)), \" took: %d(s)\" % (end_time - start_time)\n",
      "            train_probas = np.concatenate([self.compute_probas(self.data['train'], i) for i in xrange(n_train_batches)])\n",
      "            train_acc = self.compute_accuracy_score(train_probas, self.data['train']['y'])\n",
      "\n",
      "            val_probas = np.concatenate([self.compute_probas(self.data['val'], i) for i in xrange(n_val_batches)])\n",
      "            val_cost = np.mean([self.compute_cost(self.data['val'], i) for i in xrange(n_val_batches)])\n",
      "            val_acc = self.compute_accuracy_score(val_probas, self.data['val']['y'])\n",
      "            print 'epoch: %i' % epoch\n",
      "            print 'train_acc: %f' % (train_acc)\n",
      "            print 'val_acc: %f, val_cost: %f' % (val_acc, val_cost)\n",
      "            if val_cost < best_val_cost or val_acc > best_val_acc:                \n",
      "                best_val_cost = min(best_val_cost, val_cost)\n",
      "                best_val_acc = max(best_val_acc, val_acc)\n",
      "                test_probas = np.concatenate([self.compute_probas(self.data['test'], i) for i in xrange(n_test_batches)])\n",
      "                test_acc = self.compute_accuracy_score(test_probas, self.data['test']['y'])\n",
      "                print '************************* test_acc: %f' % (test_acc)\n",
      "            else:\n",
      "                pass\n",
      "        #test_wups09, test_wups00 = self.compute_wups_scores(test_probas, self.data['test']['y'])\n",
      "        #print 'test_wups0.9: %f, test_wups0.0: %f' % (test_wups09, test_wups00)\n",
      "        \n",
      "        return test_acc#, test_wups09, test_wups00\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab = Counter()\n",
      "for line in X_train_val + X_test:\n",
      "    words = line.split()\n",
      "    for word in words:\n",
      "        vocab[word] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "USE_GLOVE = True\n",
      "if USE_GLOVE:\n",
      "    if os.path.isfile('glove_embeddings.pkl'):\n",
      "        glove_embeddings = cPickle.load(open('glove_embeddings.pkl'))\n",
      "    else:\n",
      "        glove_embeddings = load_glove_vec(GLOVE_FILE, vocab)\n",
      "        cPickle.dump(glove_embeddings, open('glove_embeddings.pkl', 'wb'))\n",
      "    W, word_idx_map = get_W(glove_embeddings, k=300)\n",
      "else:\n",
      "    rand_vecs = {}\n",
      "    add_unknown_words(rand_vecs, vocab, min_df=1)\n",
      "    W, word_idx_map = get_W(rand_vecs, k=300)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for key in dataset.keys():\n",
      "    data = dataset[key]['q']\n",
      "    for i in xrange(len(data)):\n",
      "        if type(data[i]) == list:\n",
      "            continue\n",
      "        data[i] = get_idx_from_sent(data[i], word_idx_map, k=300)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = cPickle.load(open(FEATURES_FILE))\n",
      "print features.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1449, 4096)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if os.path.isfile('IMAGES.pkl'):\n",
      "    IMAGES = cPickle.load(open('IMAGES.pkl'))\n",
      "else:\n",
      "    IMAGES = np.array([preprocess_image(scipy.misc.imread(f)) for f in IMG_LIST], dtype=theano.config.floatX)\n",
      "    cPickle.dump(IMAGES, open('IMAGES.pkl', 'wb'), protocol=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = Model(dataset,\n",
      "              W.astype(theano.config.floatX),\n",
      "              np.array(IMAGES, dtype=theano.config.floatX),\n",
      "              num_output=len(mlb.classes_),\n",
      "              img_w=300,\n",
      "              hidden_size=200,\n",
      "              batch_size=BATCH_SIZE,\n",
      "              lr=0.001,\n",
      "              fine_tune_W=True,\n",
      "              optimizer='adam',\n",
      "              use_lstm=True,\n",
      "              is_bidirectional=False,\n",
      "              learn_init=False,\n",
      "              use_peepholes=False\n",
      "              )\n",
      "model.train(100, shuffle_batch=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/npow/code/nntools/lasagne/layers/base.py:91: UserWarning: layer.get_output_shape() is deprecated and will be removed for the first release of Lasagne. Please use layer.output_shape instead.\n",
        "  warnings.warn(\"layer.get_output_shape() is deprecated and will be \"\n",
        "/home/npow/code/nntools/lasagne/layers/base.py:101: UserWarning: layer.get_output(...) is deprecated and will be removed for the first release of Lasagne. Please use lasagne.layers.get_output(layer, ...) instead.\n",
        "  warnings.warn(\"layer.get_output(...) is deprecated and will be \"\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/npow/code/nntools/lasagne/layers/helper.py:68: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n",
        "  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n",
        "/home/npow/code/Theano/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
        "  from scan_perform.scan_perform import *\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cost:  5.38756570642  took: 329(s)\n",
        "epoch: 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.070312\n",
        "val_acc: 0.060547, val_cost: 4.944311\n",
        "************************* test_acc: 0.073017"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.99647633714  took: 329(s)\n",
        "epoch: 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.122975\n",
        "val_acc: 0.121094, val_cost: 4.511629\n",
        "************************* test_acc: 0.135517"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.68548426807  took: 330(s)\n",
        "epoch: 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.146991\n",
        "val_acc: 0.140625, val_cost: 4.259674\n",
        "************************* test_acc: 0.153546"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.51531373709  took: 330(s)\n",
        "epoch: 4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.162037\n",
        "val_acc: 0.134766, val_cost: 4.102500\n",
        "************************* test_acc: 0.155950"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.42641747065  took: 330(s)\n",
        "epoch: 5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.187211\n",
        "val_acc: 0.171875, val_cost: 4.063120\n",
        "************************* test_acc: 0.182993"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.24453116467  took: 330(s)\n",
        "epoch: 6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.212674\n",
        "val_acc: 0.203125, val_cost: 3.868040\n",
        "************************* test_acc: 0.211538"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4.07571376428  took: 330(s)\n",
        "epoch: 7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.229167\n",
        "val_acc: 0.191406, val_cost: 3.899165\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.92906819953  took: 329(s)\n",
        "epoch: 8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.251157\n",
        "val_acc: 0.201172, val_cost: 3.710891\n",
        "************************* test_acc: 0.249399"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.79749427446  took: 330(s)\n",
        "epoch: 9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.267940\n",
        "val_acc: 0.220703, val_cost: 3.606007\n",
        "************************* test_acc: 0.246394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.7246805932  took: 330(s)\n",
        "epoch: 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.279514\n",
        "val_acc: 0.226562, val_cost: 3.581551\n",
        "************************* test_acc: 0.258714"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.66256751506  took: 330(s)\n",
        "epoch: 11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.278356\n",
        "val_acc: 0.232422, val_cost: 3.494886\n",
        "************************* test_acc: 0.256911"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.67807701509  took: 330(s)\n",
        "epoch: 12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.260706\n",
        "val_acc: 0.224609, val_cost: 3.617220\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.85542928426  took: 330(s)\n",
        "epoch: 13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.268519\n",
        "val_acc: 0.236328, val_cost: 3.594786\n",
        "************************* test_acc: 0.249099"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.81809783768  took: 330(s)\n",
        "epoch: 14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.264178\n",
        "val_acc: 0.207031, val_cost: 3.604990\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.87216153217  took: 330(s)\n",
        "epoch: 15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.249711\n",
        "val_acc: 0.189453, val_cost: 3.672684\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.78807293093  took: 330(s)\n",
        "epoch: 16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.267072\n",
        "val_acc: 0.214844, val_cost: 3.582413\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.7140126775  took: 330(s)\n",
        "epoch: 17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.289641\n",
        "val_acc: 0.226562, val_cost: 3.554254\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.66590204504  took: 329(s)\n",
        "epoch: 18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.299190\n",
        "val_acc: 0.222656, val_cost: 3.594917\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.60025437618  took: 330(s)\n",
        "epoch: 19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.291377\n",
        "val_acc: 0.234375, val_cost: 3.650846\n",
        "cost: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.60669486369  took: 331(s)\n",
        "epoch: 20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "train_acc: 0.301505\n",
        "val_acc: 0.226562, val_cost: 3.641166\n",
        "cost: "
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "QQ,AA,II=load_file(TRAIN_FILE)\n",
      "binarizer_train = LabelBinarizer()\n",
      "binarizer_train.fit(AA)\n",
      "print len(binarizer_train.classes_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "QQ_test,AA_test,II_test=load_file(TEST_FILE)\n",
      "binarizer_test = LabelBinarizer()\n",
      "binarizer_test.fit(AA_test)\n",
      "print len(binarizer_test.classes_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"train answers: \", len(set(binarizer_train.classes_))\n",
      "print \"test answers: \", len(set(binarizer_test.classes_))\n",
      "print \"total answers: \", len(set(binarizer_train.classes_) | set(binarizer_test.classes_))\n",
      "print \"only in train: \", set(binarizer_train.classes_).difference(set(binarizer_test.classes_))\n",
      "print \"only in test:  \", set(binarizer_test.classes_).difference(set(binarizer_train.classes_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}